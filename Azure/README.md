# Azure  



### cloud concepts  

IaaS, PaaS, SaaS  

### Azure architecture and services  

Azure regional, regional pairs, and sovereign regions  

availability zones  
Azure datacenters  
Azure resources and resource groups  
scribe subscriptions  
management groups  
resource groups, subscriptions, and management groups  
Azure compute and networking services  
  
  
  
Azure compute types, including container instances, virtual machines (VMs), and functions  
  
VM options, including Azure Virtual Machines, Azure Virtual Machine Scale Sets, availability sets, and Azure Virtual Desktop  
resources required for virtual machines  
application hosting options, including the Web Apps feature of Azure App Service, containers, and virtual machines  
virtual networking, Azure Virtual Networks, Azure virtual subnets, peering, Azure DNS, Azure VPN Gateway, and Azure ExpressRoute  
public and private endpoints  
Azure storage services, storage tiers  
redundancy options  
storage account options and storage types  
options for moving files, including AzCopy, Azure Storage Explorer, and Azure File Sync  
migration options, including Azure Migrate and Azure Data Box  
  
  
  
Azure identity, access, and security  
directory services in Azure, including Azure Active Directory (Azure AD) and Azure  
Active Directory Domain Services (Azure AD DS)  
authentication methods in Azure, including single sign-on (SSO), multifactor authentication, and passwordless  
external identities and guest access in Azure  
Azure AD Conditional Access  
Azure role-based access control (RBAC)  
Zero Trust  
defense in depth model  
Microsoft Defender for Cloud  
  
  
### Azure management and  governance    
  
cost management in Azure  
factors that can affect costs in Azure  
Pricing calculator and the Total Cost of Ownership (TCO) calculator  
  
Azure Cost Management and Billing tool  
purpose of tags  
features and tools in Azure for governance and compliance  
purpose of Azure Blueprints  
purpose of Azure Policy  
purpose of resource locks  
purpose of the Service Trust Portal  
  
features and tools for managing and deploying Azure resources  
Azure portal  
Azure Cloud Shell, including Azure CLI and Azure PowerShell  
purpose of Azure Arc  
Azure Resource Manager and Azure Resource Manager templates (ARM templates)  
  
monitoring tools in Azure  
purpose of Azure Advisor  
Azure Service Health  
Azure Monitor, including Log Analytics, Azure Monitor alerts, and Application Insights  




## Compute

Access cloud compute capacity and scale on demand—and only pay for the resources you use  
  
App Service  
Quickly create powerful cloud apps for web and mobile  
  
Azure CycleCloud  
Create, manage, operate and optimise HPC and big compute clusters of any scale  
  
Azure Quantum  
Experience quantum impact today on Azure  
  
Azure Spot Virtual Machines  
Provision unused compute capacity at deep discounts to run interruptible workloads  
  
Azure Spring Cloud  
A fully managed Spring Cloud service, jointly built and operated with VMware  
  
Azure VMware Solution  
Run your VMware workloads natively on Azure  
  
Batch  
Cloud-scale job scheduling and compute management  
  
Cloud Services  
Create highly-available, infinitely-scalable cloud applications and APIs  
  
Linux Virtual Machines  
Provision virtual machines for Ubuntu, Red Hat and more  
  
SQL Server on Virtual Machines  
Host enterprise SQL Server apps in the cloud  
  
Static Web Apps  
A modern web app service that offers streamlined full-stack development from source code to global high availability  
  
Virtual Machine Scale Sets  
Manage and scale up to thousands of Linux and Windows virtual machines  
  
Virtual Machines  
Provision Windows and Linux virtual machines in seconds  
  
Azure Virtual Desktop  
Enable a secure, remote desktop experience from anywhere  
  
Azure Dedicated Host  
A dedicated physical server to host your Azure VMs for Windows and Linux  
  
Azure VM Image Builder  
Simplify your image building process with easy to use tool  
  
Azure Kubernetes Service (AKS)  
Build and scale with managed Kubernetes  
  
Azure Functions  
Process events with serverless code  
  
Container Instances  
Easily run containers on Azure without managing servers  
  
Service Fabric  
Develop microservices and orchestrate containers on Windows or Linux  
  
  
  
  
  
## Containers  
  
Develop and manage your containerised applications faster with integrated tools  
  
App Configuration  
Fast, scalable parameter storage for app configuration  
  
Azure Kubernetes Service (AKS)  
Build and scale with managed Kubernetes  
  
Azure Red Hat OpenShift  
Fully managed OpenShift service, jointly operated with Red Hat  
  
Azure Container Apps  
Build and deploy modern apps and microservices using serverless containers  
  
Azure Functions  
Process events with serverless code  
  
Web App for Containers  
Easily deploy and run containerized web apps on Windows and Linux  
  
Container Instances  
Easily run containers on Azure without managing servers  
  
Service Fabric  
Develop microservices and orchestrate containers on Windows or Linux  
  
Container Registry  
Store and manage container images across all types of deployments  
  
  
  
## Databases  
  
Support rapid growth and innovate faster with secure, enterprise-grade and fully managed database services  
  
Azure Cache for Redis  
Accelerate applications with high-throughput, low-latency data caching  
  
Azure Cosmos DB  
Fast NoSQL database with open APIs for any scale  
  
Data Factory  
Hybrid data integration at enterprise scale, made easy  
  
Azure Database for MariaDB  
Managed MariaDB database service for app developers  
  
Azure Database for MySQL  
Fully managed, scalable MySQL Database  
  
Azure Database for PostgreSQL  
Fully managed, intelligent and scalable PostgreSQL  
  
Azure Database Migration Service  
Simplify on-premises database migration to the cloud  
  
Azure SQL  
Managed, always up-to-date SQL instance in the cloud  
  
Azure SQL Database  
Managed, intelligent SQL in the cloud  
  
Azure SQL Edge  
Consume Services privately on Azure Platform  
  
Azure SQL Managed Instance  
Managed, always up-to-date SQL instance in the cloud  
  
SQL Server on Virtual Machines  
Host enterprise SQL Server apps in the cloud  
  
Table Storage  
NoSQL key-value store using semi-structured datasets  
  
Azure Managed Instance for Apache Cassandra  
Cloud Cassandra with flexibility, control and scale  
  
Microsoft Azure Confidential Ledger Preview  
Easily use a REST API managed service to store your unstructured metadata in a blockchain structure  
  
  
  
  
  
  
## Developer Tools  
  
Build, manage and continuously deliver cloud applications—using any platform or language  
  
App Configuration  
Fast, scalable parameter storage for app configuration  
  
Azure DevOps  
Services for teams to share code, track work and ship software  
  
Azure DevTest Labs  
Quickly create environments using reusable templates and artifacts  
  
Azure Lab Services  
Set up labs for classrooms, trials, development and testing and other scenarios  
  
Azure Pipelines  
Continuously build, test and deploy to any platform and cloud  
  
SDKs  
Get the SDKs and command-line tools you need  
  
Visual Studio  
The powerful and flexible environment for developing applications in the cloud  
  
Visual Studio Code  
A powerful, lightweight code editor for cloud development  
  
Azure Load Testing Preview  
Optimize app performance with high-scale load testing  
  
  
  
  
  
## DevOps  
  
Deliver innovation faster with simple, reliable tools for continuous delivery  
  
Azure Artifacts  
Create, host and share packages with your team  
  
Azure Boards  
Plan, track and discuss work across your teams  
  
Azure DevOps  
Services for teams to share code, track work and ship software  
  
Azure DevTest Labs  
Quickly create environments using reusable templates and artifacts  
  
Azure Monitor  
Full observability into your apps, infrastructure, and network  
  
Azure Pipelines  
Continuously build, test and deploy to any platform and cloud  
  
Azure Repos  
Get unlimited, cloud-hosted private Git repos for your project  
  
Azure Test Plans  
Test and ship with confidence with a manual and exploratory testing toolkit  
  
DevOps tool integrations  
Use your favourite DevOps tools with Azure  
  
Azure Load Testing Preview  
Optimize app performance with high-scale load testing  
  
Azure Managed Grafana Preview  
Deploy Grafana dashboards as a fully managed Azure service  
  
  
  
  
  
## Hybrid + multicloud  
  
Get Azure innovation everywhere—bring the agility and innovation of cloud computing to your on-premises workloads  
  
Azure Active Directory  
Synchronise on-premises directories and enable single sign-on  
  
Azure Arc  
Extend Azure management and services anywhere  
  
Azure Database for PostgreSQL  
Fully managed, intelligent and scalable PostgreSQL  
  
Azure DevOps  
Services for teams to share code, track work and ship software  
  
Azure ExpressRoute  
Dedicated private network fiber connections to Azure  
  
Azure IoT Edge  
Extend cloud intelligence and analytics to edge devices managed by Azure IoT Hub  
  
Azure Sentinel  
Put cloud-native SIEM and intelligent security analytics to work to help protect your enterprise  
  
Azure SQL Database  
Managed, intelligent SQL in the cloud  
  
Azure SQL Edge  
Consume Services privately on Azure Platform  
  
Azure Stack  
Build and run innovative hybrid applications across cloud boundaries  
  
Security Center  
Unify security management and enable advanced threat protection across hybrid cloud workloads  
  
Azure Stack HCI  
Run your production workloads anywhere on hybrid, familiar hyperconverged infrastructure  
  
Azure Stack Hub  
Azure Stack Hub is sold as an integrated hardware system, with software pre-installed on validated hardware  
  
Azure Stack Edge  
An Azure managed device that brings the compute, storage and intelligence of Azure to the edge  
  
Azure Modular Datacenter  
A complete, rugged datacenter solution  
  
  
  
  
## Identity  
  
Manage user identities and access to protect against advanced threats across devices, data, apps, and infrastructure  
  
Azure Active Directory  
Synchronise on-premises directories and enable single sign-on  
  
Azure Active Directory Domain Services  
Join Azure virtual machines to a domain without domain controllers  
  
Azure Information Protection  
Better protect your sensitive information—anytime, anywhere  
  
Azure Active Directory External Identities  
Consumer identity and access management in the cloud  
  
  
  
  
  
  
## Integration  
  
Seamlessly integrate on-premises and cloud-based applications, data and processes across your enterprise  
  
API Management  
Publish APIs to developers, partners, and employees securely and at scale  
  
Azure Healthcare APIs  
A unified solution that helps protect and combine health data in the cloud and generates healthcare insights with analytics  
  
Event Grid  
Reliable event delivery at massive scale  
  
Logic Apps  
Automate the access and use of data across clouds  
  
Service Bus  
Connect across private and public cloud environments  
  
Azure Web PubSub  
Easily build real-time messaging web applications using WebSockets and the publish-subscribe pattern  
  
  
  
  
  
  
## Management and Governance  
  
Simplify, automate and optimise the management and compliance of your cloud resources  
  
Automation  
Simplify cloud management with process automation  
  
Azure Advisor  
Your personalised Azure best practices recommendation engine  
  
Azure Backup  
Simplify data protection and protect against ransomware  
  
Azure Blueprints Preview  
Enabling quick, repeatable creation of governed environments  
  
Azure Lighthouse  
Empowering service providers to manage customers at scale and with precision  
  
Azure Managed Applications  
Simplify management of cloud offerings  
  
Azure Migrate  
Discover, assess, right-size, and migrate your on-premises virtual machines (VMs) to Azure  
  
Azure mobile app  
Stay connected to your Azure resources—anytime, anywhere  
  
Azure Monitor  
Full observability into your apps, infrastructure, and network  
  
Azure Policy  
Implement corporate governance and standards at scale for Azure resources  
  
Azure Resource Manager  
Simplify how you manage your app resources  
  
Azure Resource Manager templates  
Deliver infrastructure as code for all your Azure resources using Resource Manager  
  
Azure Service Health  
Personalized guidance and support for when issues in Azure services affect you  
  
Azure Site Recovery  
Keep your business running with built-in disaster recovery service  
  
Cloud Shell  
Streamline Azure administration with a browser-based shell  
  
Azure Cost Management and Billing  
Manage your cloud spending with confidence  
  
Microsoft Azure portal  
Build, manage, and monitor all Azure products in a single, unified console  
  
Network Watcher  
Network performance monitoring and diagnostics solution  
  
Traffic Manager  
Route incoming traffic for high performance and availability  
  
Azure Automanage Preview  
Simplify and optimise IT management with automated operations  
  
Azure Resource Mover  
Simplify how you move multiple resources between Azure regions  
  
Azure Purview  
A unified data governance solution that maximizes the business value of your data  
  
Azure Chaos Studio Preview  
Improve application resilience by introducing faults and simulating outages  
  
Azure Managed Grafana Preview  
Deploy Grafana dashboards as a fully managed Azure service  






## Media

Deliver high-quality video content anywhere, any time and on any device

Azure Media Player
A single player for all your playback needs

Content Delivery Network
Ensure secure, reliable content delivery with broad global reach

Content Protection
Securely deliver content using AES, PlayReady, Widevine and Fairplay

Encoding
Studio grade encoding at cloud scale

Live and On-Demand Streaming
Deliver content to virtually all devices with scale to meet business needs

Media Services
Encode, store, and stream video and audio at scale






## Migration

Simplify and accelerate your migration to the cloud with guidance, tools and resources

Azure Database Migration Service
Simplify on-premises database migration to the cloud

Azure Migrate
Discover, assess, right-size, and migrate your on-premises virtual machines (VMs) to Azure

Azure Site Recovery
Keep your business running with built-in disaster recovery service

Azure Cost Management and Billing
Manage your cloud spending with confidence

Data Box
Appliances and solutions for data transfer to Azure and edge compute






## Networking

Connect cloud and on-premises infrastructure and services to provide your customers and users the best possible experience

Application Gateway
Build secure, scalable and highly available web front ends in Azure

Azure Bastion
Private and fully managed RDP and SSH access to your virtual machines

Azure DDoS Protection
Protect your applications from Distributed Denial of Service (DDoS) attacks

Azure DNS
Host your DNS domain in Azure

Azure ExpressRoute
Dedicated private network fiber connections to Azure

Azure Firewall
Cloud-native, next-generation firewall to protect your Azure Virtual Network resources

Load Balancing
Explore Azure load balancing services and find the best solution for your workloads using an easy-to-use service selection tool

Azure Firewall Manager
Central network security policy and route management for globally distributed, software-defined perimeters

Azure Front Door Standard/Premium (Preview)
Scalable, security-enhanced delivery point for global, microservice-based web applications

Azure Internet Analyzer Preview
Test how networking infrastructure changes will impact your customers' performance.

Azure Private Link
Private access to services hosted on the Azure platform, keeping your data on the Microsoft network

Content Delivery Network
Ensure secure, reliable content delivery with broad global reach

Network Watcher
Network performance monitoring and diagnostics solution

Traffic Manager
Route incoming traffic for high performance and availability

Virtual Network
Provision private networks, optionally connect to on-premises datacenters

Virtual WAN
Optimise and automate branch to branch connectivity through Azure

VPN Gateway
Establish secure, cross-premises connectivity

Web Application Firewall
A cloud-native web application firewall (WAF) service that provides powerful protection for web apps

Azure Orbital Preview
Satellite ground station and scheduling service connected to Azure for fast downlinking of data

Azure Route Server
Enable network appliances to exchange routes dynamically with virtual networks in Azure

Azure Network Function Manager
Extend Azure management for deploying 5G and SD-WAN network functions on edge devices

Azure Virtual Network Manager Preview
Centrally manage virtual networks in Azure from a single pane of glass

Azure Private 5G Core Preview
Rapidly deploy and manage private 5G networks at the enterprise edge




## Security

Protect your enterprise from advanced threats across hybrid cloud workloads

App Configuration
Fast, scalable parameter storage for app configuration

Application Gateway
Build secure, scalable and highly available web front ends in Azure

Azure Active Directory
Synchronise on-premises directories and enable single sign-on

Azure Active Directory Domain Services
Join Azure virtual machines to a domain without domain controllers

Microsoft Defender for Cloud
Protect your multi-cloud and hybrid environments

Azure Bastion
Private and fully managed RDP and SSH access to your virtual machines

Azure DDoS Protection
Protect your applications from Distributed Denial of Service (DDoS) attacks

Azure Dedicated HSM
Manage hardware security modules that you use in the cloud

Azure Firewall
Cloud-native, next-generation firewall to protect your Azure Virtual Network resources

Azure Firewall Manager
Central network security policy and route management for globally distributed, software-defined perimeters

Azure Front Door Standard/Premium (Preview)
Scalable, security-enhanced delivery point for global, microservice-based web applications

Azure Information Protection
Better protect your sensitive information—anytime, anywhere

Azure Sentinel
Put cloud-native SIEM and intelligent security analytics to work to help protect your enterprise

Key Vault
Safeguard and maintain control of keys and other secrets

Security Center
Unify security management and enable advanced threat protection across hybrid cloud workloads

VPN Gateway
Establish secure, cross-premises connectivity

Web Application Firewall
A cloud-native web application firewall (WAF) service that provides powerful protection for web apps

Azure Defender for IoT
Monitor and detect security threats to both managed and unmanaged IoT assets

Microsoft Azure Attestation
A unified solution for remotely verifying the trustworthiness of a platform and integrity of the binaries running inside it

Microsoft Azure Confidential Ledger Preview
Easily use a REST API managed service to store your unstructured metadata in a blockchain structure




## Storage

Get secure, massively scalable cloud storage for your data, apps and workloads
Industry leading price point for storing rarely accessed data

Avere vFXT for Azure
Run high-performance, file-based workloads in the cloud

Azure Backup
Simplify data protection and protect against ransomware

Azure Data Lake Storage
Massively scalable, secure data lake functionality built on Azure Blob Storage

Azure Data Lake Storage Gen1
Hyperscale repository for big data analytics workloads

Azure Data Share
A simple and safe service for sharing big data with external organizations

Azure Files
Simple, secure and serverless enterprise-grade cloud file shares

Azure FXT Edge Filer
Hybrid storage optimisation solution for HPC environments

Azure HPC Cache
File caching for high-performance computing (HPC)

Azure NetApp Files
Enterprise-grade Azure file shares, powered by NetApp

Azure Blob Storage
Massively scalable and secure object storage

Data Box
Appliances and solutions for data transfer to Azure and edge compute

Azure Disk Storage
High-performance, highly durable block storage

Queue Storage
Effectively scale apps according to traffic

Storage Accounts
Durable, highly available and massively scalable cloud storage

Storage Explorer
View and interact with Azure Storage resources

StorSimple
Lower costs with an enterprise hybrid cloud storage solution

Microsoft Azure Confidential Ledger Preview
Easily use a REST API managed service to store your unstructured metadata in a blockchain structure







## Analytics

Gather, store, process, analyse and visualise data of any variety, volume or velocity

Azure Analysis Services
Enterprise-grade analytics engine as a service

Azure Data Explorer
Fast and highly scalable data exploration service

Data Factory
Hybrid data integration at enterprise scale, made easy

Azure Data Lake Storage
Massively scalable, secure data lake functionality built on Azure Blob Storage

Azure Data Lake Storage Gen1
Hyperscale repository for big data analytics workloads

Azure Data Share
A simple and safe service for sharing big data with external organizations

Azure Databricks
Design AI with Apache Spark™-based analytics

Azure Stream Analytics
Real-time analytics on fast-moving streaming data

Azure Synapse Analytics
Limitless analytics service with unmatched time to insight

Data Catalog
Get more value from your enterprise data assets

Data Lake Analytics
Distributed analytics service which makes big data easy

Event Hubs
Receive telemetry from millions of devices

HDInsight
Provision cloud Hadoop, Spark, R Server, HBase, and Storm clusters

Power BI Embedded
White label Power BI to quickly and easily provide exceptional customer facing dashboards and analytics in your own applications

R Server for HDInsight
Predictive analytics, machine learning and statistical modeling for big data

Azure Purview
A unified data governance solution that maximizes the business value of your data

Microsoft Graph Data Connect Preview
A secure, high-throughput connector designed to copy select Microsoft 365 productivity datasets into your Azure tenant

Azure Chaos Studio Preview
Improve application resilience by introducing faults and simulating outages






Types of Availability Sets:  

i. Fault Domain: It denotes a cluster of VMs that share common power sources and identical networks.  

ii. Updated Domain: It denotes a group of Virtual Machines that simultaneously accomplish activities like reboot, maintenance, and update.   
     		    If you want to obtain maximum availability, you need to deploy VMs across multiple Fault Domains.   





---
Amazing Microsoft Resources AZ-204 exam:


[Learning paths on MS Learn](https://docs.microsoft.com/en-us/learn/certifications/exams/az-204#two-ways-to-prepare)  


[Azure Code Samples:](https://azure.microsoft.com/en-us/resources/samples/?sort=0)  


[Official Azure Documentation:](https://docs.microsoft.com/en-us/azure/)  


[Official Microsoft Azure YouTube Channel](https://www.youtube.com/user/windowsazure)  


[Official Microsoft Developer YouTube Channel](https://www.youtube.com/channel/UCsMica-v34Irf9KVTh6xx-g)  


[Azure REST API Browser](https://docs.microsoft.com/en-us/rest/api/?view=Azure)  


[Azure Citadel - Labs and Workshops](https://azurecitadel.com/)  


[Microsoft Cloud Workshop - More labs and workshops](https://microsoftcloudworkshop.com/)  


[Github AZ-204 from Microsoft Training](https://microsoftlearning.github.io/AZ-204-DevelopingSolutionsforMicrosoftAzure/)  


[Microsoft has a Github page that contains labs for AZ-204:](https://github.com/MicrosoftLearning/AZ-204-DevelopingSolutionsforMicrosoftAzure)  

---





# Notes  


```
There are two ways to scale your Redis (cluster mode enabled) cluster; horizontal and vertical scaling.

    Horizontal scaling allows you to change the number of node groups (shards) in the replication group by adding or removing node groups (shards). The online resharding process allows scaling in/out while the cluster continues serving incoming requests.

    Configure the slots in your new cluster differently than they were in the old cluster. Offline method only.

    Vertical Scaling - Change the node type to resize the cluster. The online vertical scaling allows scaling up/down while the cluster continues serving incoming requests.

Redis Cluster supports up to 10 shards to create 1.2 TB of memory.




Policies allow you to modify the inbound request as well as the outbound results without modifying the API code itself.



Core (SQL) API stores data in JSON document format. 
Cassandra API stores data in column-oriented schema. 
Gremlin(Graph) API allows users to make graph queries and stores data as edges and vertices. 
MongoDB API also uses documents but is BSON format, which is a binary format and not text-based. 
Refer to Microsoft Doc: https://docs.microsoft.com/en-us/azure/cosmos-db/introduction



Service Bus Queue is enterprise-grade message queue.




Service 	Purpose 		Type 	When to use
Event Grid 	Reactive programming 	Event distribution (discrete) 	React to status changes
Event Hubs 	Big data pipeline 	Event streaming (series) 	Telemetry and distributed data streaming
Service Bus 	High-value enterprise  	Message 			Order processing and 
		messaging						financial transactions




1 throughput unit represent 1 MB per second or 1000 events per second (whichever comes first) data coming in to an Event Hub 




Managed identity types

There are two types of managed identities:

    System-assigned. Some Azure services allow you to enable a managed identity directly on a service instance. When you enable a system-assigned managed identity, an identity is created in Azure AD. The identity is tied to the lifecycle of that service instance. When the resource is deleted, Azure automatically deletes the identity for you. By design, only that Azure resource can use this identity to request tokens from Azure AD.
    User-assigned. You may also create a managed identity as a standalone Azure resource. You can create a user-assigned managed identity and assign it to one or more instances of an Azure service. For user-assigned managed identities, the identity is managed separately from the resources that use it. 



Property 	System-assigned managed identity 		User-assigned managed identity
Creation 	Created as part of an Azure resource (for example, Azure Virtual Machines or Azure App Service). 	Created as a stand-alone Azure resource.
Life cycle 	Shared life cycle with the Azure resource that the managed identity is created with.
When the parent resource is deleted, the managed identity is deleted as well. 	Independent life cycle.
Must be explicitly deleted.
Sharing across Azure resources 	Can’t be shared.
It can only be associated with a single Azure resource. 	Can be shared.
The same user-assigned managed identity can be associated with more than one Azure resource.
Common use cases 	Workloads that are contained within a single Azure resource.
Workloads for which you need independent identities.
For example, an application that runs on a single virtual machine. 	Workloads that run on multiple resources and can share a single identity.
Workloads that need pre-authorization to a secure resource, as part of a provisioning flow.
Workloads where resources are recycled frequently, but permissions should stay consistent.
For example, a workload where multiple virtual machines need to access the same resource.






ASP.NET

ASP.NET apps only run on Windows app services. To log information to the app diagnostics log, use the System.Diagnostics.Trace class. There are four trace levels you can use, and these correlate with error, warning, information, and verbose logging levels shown in the Azure portal:

    Trace.TraceError("Message"); // Writes an error message
    Trace.TraceWarning("Message"); // Writes a warning message
    Trace.TraceInformation("Message"); // Writes an information message
    Trace.WriteLine("Message"); // Writes a verbose message

ASP.NET Core apps

ASP.NET Core apps can run on either Windows or Linux. To log information to Azure app logs, use the logger factory class, and then use one of six-log levels:

    logger.LogCritical("Message"); // Writes a critical message at log level 5
    logger.LogError("Message"); // Writes an error message at log level 4
    logger.LogWarning("Message"); // Writes a warning message at log level 3
    logger.LogInformation("Message"); // Writes an information message at log level 2
    logger.LogDebug("Message"); // Writes a debug message at log level 1
    logger.LogTrace("Message"); // Writes a detailed trace message at log level 0

For ASP.NET Core apps on Windows, these messages relate to the filters in the Azure portal in this way:

    Levels 4 and 5 are "error" messages.
    Level 3 is a "warning" message.
    Level 2 is an "information" message.
    Levels 0 and 1 are "verbose" messages.

For ASP.NET Core apps on Linux, only "error" messages (levels 4 and 5) are logged.
Node.js apps

For script-based Web apps, such as Node.js apps on Windows or Linux, app logging is enabled using the console() method:

    console.error("Message") - writes a message to STDERR
    console.log("Message") - writes a message to STDOUT

Both types of message are written to the Azure app service error-level logs.








A shared access signature (SAS) provides secure delegated access to resources in your storage account. With a SAS, you have granular control over how a client can access your data. For example:

    What resources the client may access.

    What permissions they have to those resources.

    How long the SAS is valid.

Types of shared access signatures

Azure Storage supports three types of shared access signatures:

    User delegation SAS

    Service SAS

    Account SAS









Durable functons  

Durable Functions is an extension of Azure Functions that lets you write stateful functions in a serverless compute environment. The extension lets you define stateful workflows by writing orchestrator functions and stateful entities by writing entity functions using the Azure Functions programming model. Behind the scenes, the extension manages state, checkpoints, and restarts for you, allowing you to focus on your business logic.



Application patterns

The primary use case for Durable Functions is simplifying complex, stateful coordination requirements in serverless applications. The following sections describe typical application patterns that can benefit from Durable Functions:

    Function chaining
    Fan-out/fan-in
    Async HTTP APIs
    Monitoring
    Human interaction
    Aggregator (stateful entities)








Azure Functions custom handlers

    Article
    12/17/2021
    12 minutes to read

Every Functions app is executed by a language-specific handler. While Azure Functions features many language handlers by default, there are cases where you may want to use other languages or runtimes.

Custom handlers are lightweight web servers that receive events from the Functions host. Any language that supports HTTP primitives can implement a custom handler.

Custom handlers are best suited for situations where you want to:

    Implement a function app in a language that's not currently offered out-of-the box, such as Go or Rust.
    Implement a function app in a runtime that's not currently featured by default, such as Deno.

With custom handlers, you can use triggers and input and output bindings via extension bundles.

Get started with Azure Functions custom handlers with quickstarts in Go and Rust.


Application structure

To implement a custom handler, you need the following aspects to your application:

    A host.json file at the root of your app
    A local.settings.json file at the root of your app
    A function.json file for each function (inside a folder that matches the function name)
    A command, script, or executable, which runs a web server









Guarantees associated with consistency levels

Azure Cosmos DB guarantees that 100 percent of read requests meet the consistency guarantee for the consistency level chosen. The precise definitions of the five consistency levels in Azure Cosmos DB using the TLA+ specification language are provided in the azure-cosmos-tla GitHub repo.

The semantics of the five consistency levels are described in the following sections.
Strong consistency

Strong consistency offers a linearizability guarantee. Linearizability refers to serving requests concurrently. The reads are guaranteed to return the most recent committed version of an item. A client never sees an uncommitted or partial write. Users are always guaranteed to read the latest committed write.


Bounded staleness consistency

In bounded staleness consistency, the reads are guaranteed to honor the consistent-prefix guarantee. The reads might lag behind writes by at most "K" versions (that is, "updates") of an item or by "T" time interval, whichever is reached first. In other words, when you choose bounded staleness, the "staleness" can be configured in two ways:

    The number of versions (K) of the item
    The time interval (T) reads might lag behind the writes

For a single region account, the minimum value of K and T is 10 write operations or 5 seconds. For multi-region accounts the minimum value of K and T is 100,000 write operations or 300 seconds.

Bounded staleness offers total global order outside of the "staleness window." When a client performs read operations within a region that accepts writes, the guarantees provided by bounded staleness consistency are identical to those guarantees by the strong consistency. As the staleness window approaches for either time or updates, whichever is closer, the service will throttle new writes to allow replication to catch up and honor the consistency guarantee.

Inside the staleness window, Bounded Staleness provides the following consistency guarantees:

    Consistency for clients in the same region for an account with single write region = Strong

    Consistency for clients in different regions for an account with single write region = Consistent Prefix

    Consistency for clients writing to a single region for an account with multiple write regions = Consistent Prefix

    Consistency for clients writing to different regions for an account with multiple write regions = Eventual

    Bounded staleness is frequently chosen by globally distributed applications that expect low write latencies but require total global order guarantee. Bounded staleness is great for applications featuring group collaboration and sharing, stock ticker, publish-subscribe/queueing etc. 


Session consistency

In session consistency, within a single client session reads are guaranteed to honor the consistent-prefix, monotonic reads, monotonic writes, read-your-writes, and write-follows-reads guarantees. This assumes a single "writer" session or sharing the session token for multiple writers.

Clients outside of the session performing writes will see the following guarantees:

    Consistency for clients in same region for an account with single write region = Consistent Prefix

    Consistency for clients in different regions for an account with single write region = Consistent Prefix

    Consistency for clients writing to a single region for an account with multiple write regions = Consistent Prefix

    Consistency for clients writing to multiple regions for an account with multiple write regions = Eventual

    Consistency for clients using the Azure Cosmos DB integrated cache = Eventual

    Session consistency is the most widely used consistency level for both single region as well as globally distributed applications. It provides write latencies, availability, and read throughput comparable to that of eventual consistency but also provides the consistency guarantees that suit the needs of applications written to operate in the context of a user. 


Consistent prefix consistency

In consistent prefix option, updates that are returned contain some prefix of all the updates, with no gaps. Consistent prefix consistency level guarantees that reads never see out-of-order writes.

If writes were performed in the order A, B, C, then a client sees either A, A,B, or A,B,C, but never out-of-order permutations like A,C or B,A,C. Consistent Prefix provides write latencies, availability, and read throughput comparable to that of eventual consistency, but also provides the order guarantees that suit the needs of scenarios where order is important.

Below are the consistency guarantees for Consistent Prefix:

    Consistency for clients in same region for an account with single write region = Consistent Prefix
    Consistency for clients in different regions for an account with single write region = Consistent Prefix
    Consistency for clients writing to a single region for an account with multiple write region = Consistent Prefix
    Consistency for clients writing to multiple regions for an account with multiple write region = Eventual




Eventual consistency

In eventual consistency, there's no ordering guarantee for reads. In the absence of any further writes, the replicas eventually converge.

Eventual consistency is the weakest form of consistency because a client may read the values that are older than the ones it had read before. Eventual consistency is ideal where the application does not require any ordering guarantees. Examples include count of Retweets, Likes, or non-threaded comments. 







```



## Exam AZ-400: Designing and Implementing Microsoft DevOps Solutions  


```

Configure processes and communications (10—15%)
Configure activity traceability and flow of work
• plan and implement a structure for the flow of work and feedback cycles
• identify appropriate metrics related to flow of work, such as cycle times, time to recovery,
and lead time• integrate pipelines with work item tracking tools, such as Azure DevOps and GitHub
• implement traceability policies decided by development
• integrate a repository with Azure Boards
Configure collaboration and communication
•
•
•
•
•
communicate actionable information by using custom dashboards in Azure DevOps
document a project by using tools, such as wikis and process diagrams
configure release documentation, including release notes and API documentation
automate creation of documentation from Git history
configure notifications by using webhooks
Design and implement source control (15—20%)
Design and implement a source control strategy
• design and implement an authentication strategy
• design a strategy for managing large files, including Git LFS and git-fat
• design a strategy for scaling and optimizing a Git repository, including Scalar and cross-
repository sharing
• implement workflow hooks
Plan and implement branching strategies for the source code
• design a branch strategy, including trunk-based, feature branch, and release branch
• design and implement a pull request workflow by using branch policies and branch
protections
• implement branch merging restrictions by using branch policies and branch protections
Configure and manage repositories
•
•
•
•
•
integrate GitHub repositories with Azure Pipelines, one of the services in Azure DevOps
configure permissions in the source control repository
configure tags to organize the source control repository
recover data by using Git commands
purge data from source control
Design and implement build and release pipelines (40—45%)
Design and implement pipeline automation
• integrate pipelines with external tools, including dependency scanning, security
scanning, and code coverage•
•
•
•
design and implement quality and release gates, including security and governance
design integration of automated tests into a pipeline
design and implement a comprehensive testing strategy
implement orchestration of tools, such as GitHub Actions and Azure Pipelines
Design and implement a package management strategy
• design a package management implementation that uses Azure Artifacts, GitHub
Packages, NuGet, and npm
• design and implement package feeds, including upstream sources
• design and implement a dependency versioning strategy for code assets and packages,
including semantic versioning and date-based
• design and implement a versioning strategy for pipeline artifacts
Design and implement pipelines
• select a deployment automation solution, including GitHub Actions and Azure Pipelines
• design and implement an agent infrastructure, including cost, tool selection, licenses,
connectivity, and maintainability
• develop and implement pipeline trigger rules
• develop pipelines, including classic and YAML
• design and implement a strategy for job execution order, including parallelism and
multi-stage
• develop complex pipeline scenarios, such as containerized agents and hybrid
• configure and manage self-hosted agents, including virtual machine (VM) templates and
containerization
• create reusable pipeline elements, including YAML templates, task groups, variables, and
variable groups
• design and implement checks and approvals by using YAML environments
Design and implement deployments
• design a deployment strategy, including blue/green, canary, ring, progressive exposure,
feature flags, and A/B testing
• design a pipeline to ensure reliable order of dependency deployments
• plan for minimizing downtime during deployments by using VIP swap, load balancer,
and rolling deployments
• design a hotfix path plan for responding to high-priority code fixes
• implement load balancing for deployment, including Azure Traffic Manager and the Web
Apps feature of Azure App Service
• implement feature flags by using Azure App Configuration Feature Manager
• implement application deployment by using containers, binary, and scriptsDesign and implement infrastructure as code (IaC)
• recommend a configuration management technology for application infrastructure
• implement a configuration management strategy for application infrastructure, including
IaC
• define an IaC strategy, including source control and automation of testing and
deployment
• design and implement desired state configuration for environments, including Azure
Automation State Configuration, Azure Resource Manager, Bicep, and Azure Policy guest
configuration
Maintain pipelines
•
•
•
•
monitor pipeline health, including failure rate, duration, and flaky tests
optimize pipelines for cost, time, performance, and reliability
analyze pipeline load to determine agent configuration and capacity
design and implement a retention strategy for pipeline artifacts and dependencies
Develop a security and compliance plan (10—15%)
Design and implement a strategy for managing sensitive information in automation
• implement and manage service connections
• implement and manage personal access tokens
• implement and manage secrets, keys, and certificates by using Azure Key Vault, GitHub
secrets, and Azure Pipelines secrets
• design and implement a strategy for managing sensitive files during deployment
• design pipelines to prevent leakage of sensitive information
Automate security and compliance scanning
• automate analysis of source code by using GitHub code scanning, GitHub secrets
scanning, pipeline-based scans, and SonarQube
• automate security scanning, including container scanning and OWASP ZAP
• automate analysis of licensing, vulnerabilities, and versioning of open-source
components by using WhiteSource and GitHub Dependency Scanning
Implement an instrumentation strategy (10—15%)
Configure monitoring for a DevOps environment
• configure and integrate monitoring by using Azure Monitor
• configure and integrate with monitoring tools, such as Azure Monitor and Application
Insights• manage access control to the monitoring platform
• configure alerts for pipeline events
Analyze metrics
• inspect distributed tracing by using Application Insights
• inspect application performance indicators
• inspect infrastructure performance indicators, including CPU, memory, disk, and network
• identify and monitor metrics for business value
• analyze usage metrics by using Application Insight
• interrogate logs using basic Kusto Query Language (KQL) queries













Skills measured

    This list contains the skills measured on the exam associated with this certification. For more detailed information, visit the exam details page and download the exam skills outline.
    Configure processes and communications
    Design and implement source control
    Design and implement build and release pipelines
    Develop a security and compliance plan
    Implement an instrumentation strategy

 





```


# AZ-400: Designing and Implementing Microsof DevOps Solutions

```

Audience Profile
DevOps engineers are developers or infrastructure administrators who also have subject matter
expertise in working with people, processes, and products to enable continuous delivery of value
in organizations.
Responsibilities for this role include designing and implementing strategies for collaboration,
code, infrastructure, source control, security, compliance, continuous integration, testing,
delivery, monitoring, and feedback.
DevOps engineers work on cross-functional teams that include developers, site reliability
engineers, and Azure administrators.
DevOps engineers must have experience with administering and developing in Azure, with
strong skills in at least one of these areas. They should be familiar with both Azure DevOps and GitHub  






Configure processes and communications (10—15%)
Configure activity traceability and flow of work
• plan and implement a structure for the flow of work and feedback cycles
• identify appropriate metrics related to flow of work, such as cycle times, time to recovery,
and lead time
• integrate pipelines with work item tracking tools, such as Azure DevOps and GitHub
• implement traceability policies decided by development
• integrate a repository with Azure Boards
Configure collaboration and communication
• communicate actionable information by using custom dashboards in Azure DevOps
• document a project by using tools, such as wikis and process diagrams
• configure release documentation, including release notes and API documentation
• automate creation of documentation from Git history
• configure notifications by using webhooks
Design and implement source control (15—20%)
Design and implement a source control strategy
• design and implement an authentication strategy
• design a strategy for managing large files, including Git LFS and git-fat
• design a strategy for scaling and optimizing a Git repository, including Scalar and cross-
repository sharing
• implement workflow hooks
Plan and implement branching strategies for the source code
• design a branch strategy, including trunk-based, feature branch, and release branch
• design and implement a pull request workflow by using branch policies and branch
protections
• implement branch merging restrictions by using branch policies and branch protections
Configure and manage repositories
• integrate GitHub repositories with Azure Pipelines, one of the services in Azure DevOps
• configure permissions in the source control repository
• configure tags to organize the source control repository
• recover data by using Git commands
• purge data from source control
Design and implement build and release pipelines (40—45%)
Design and implement pipeline automation
• integrate pipelines with external tools, including dependency scanning, security
scanning, and code coverage
• design and implement quality and release gates, including security and governance
• design integration of automated tests into a pipeline
• design and implement a comprehensive testing strategy
• implement orchestration of tools, such as GitHub Actions and Azure Pipelines
Design and implement a package management strategy
• design a package management implementation that uses Azure Artifacts, GitHub
Packages, NuGet, and npm
• design and implement package feeds, including upstream sources
• design and implement a dependency versioning strategy for code assets and packages,
including semantic versioning and date-based
• design and implement a versioning strategy for pipeline artifacts
Design and implement pipelines
• select a deployment automation solution, including GitHub Actions and Azure Pipelines
• design and implement an agent infrastructure, including cost, tool selection, licenses,
connectivity, and maintainability
• develop and implement pipeline trigger rules
• develop pipelines, including classic and YAML
• design and implement a strategy for job execution order, including parallelism and
multi-stage
• develop complex pipeline scenarios, such as containerized agents and hybrid
• configure and manage self-hosted agents, including virtual machine (VM) templates and
containerization
• create reusable pipeline elements, including YAML templates, task groups, variables, and
variable groups
• design and implement checks and approvals by using YAML environments
Design and implement deployments
• design a deployment strategy, including blue/green, canary, ring, progressive exposure,
feature flags, and A/B testing
• design a pipeline to ensure reliable order of dependency deployments
• plan for minimizing downtime during deployments by using VIP swap, load balancer,
and rolling deployments
• design a hotfix path plan for responding to high-priority code fixes
• implement load balancing for deployment, including Azure Traffic Manager and the Web
Apps feature of Azure App Service
• implement feature flags by using Azure App Configuration Feature Manager
• implement application deployment by using containers, binary, and scripts
Design and implement infrastructure as code (IaC)
• recommend a configuration management technology for application infrastructure
• implement a configuration management strategy for application infrastructure, including
IaC
• define an IaC strategy, including source control and automation of testing and
deployment
• design and implement desired state configuration for environments, including Azure
Automation State Configuration, Azure Resource Manager, Bicep, and Azure Policy guest
configuration
Maintain pipelines
• monitor pipeline health, including failure rate, duration, and flaky tests
• optimize pipelines for cost, time, performance, and reliability
• analyze pipeline load to determine agent configuration and capacity
• design and implement a retention strategy for pipeline artifacts and dependencies
Develop a security and compliance plan (10—15%)
Design and implement a strategy for managing sensitive information in automation
• implement and manage service connections
• implement and manage personal access tokens
• implement and manage secrets, keys, and certificates by using Azure Key Vault, GitHub
secrets, and Azure Pipelines secrets
• design and implement a strategy for managing sensitive files during deployment
• design pipelines to prevent leakage of sensitive information
Automate security and compliance scanning
• automate analysis of source code by using GitHub code scanning, GitHub secrets
scanning, pipeline-based scans, and SonarQube
• automate security scanning, including container scanning and OWASP ZAP
• automate analysis of licensing, vulnerabilities, and versioning of open-source
components by using WhiteSource and GitHub Dependency Scanning
Implement an instrumentation strategy (10—15%)
Configure monitoring for a DevOps environment
• configure and integrate monitoring by using Azure Monitor
• configure and integrate with monitoring tools, such as Azure Monitor and Application
Insights
• manage access control to the monitoring platform
• configure alerts for pipeline events
Analyze metrics
• inspect distributed tracing by using Application Insights
• inspect application performance indicators
• inspect infrastructure performance indicators, including CPU, memory, disk, and network
• identify and monitor metrics for business value
• analyze usage metrics by using Application Insight
• interrogate logs using basic Kusto Query Language (KQL) queries  






Developing Security and Compliance  

automate
container scanning  
OWASP
depndency scanning 
licenses: MIT,GPL  
asess and report risks
source code compliance solution
github code scanning
github secret scanning
pipeline-based scans
git hooks
SonarQube
Dependabot
Azure DevOps
Github
DevSecOps

Static Application Security Testing (SAST) 
White Box testing done during CI and PR
SonarCloud
PMD static analysis tool


Dynamic Application Security Testing (SAST) 
testing a deployed application
balck box testing
indentify common security vulnerabilities
OWASP ZAP
ZAP Zed Attack Proxy
Free and Open Source
Passive scan
fast running
Active scan
long running
nightly builds 

Dependency scanning
scanning libraries, packages, etc
National Vulnerability Database (NVD) 
Permissive license
Copyleft license
WhiteSource Bolt
Black Duck or Synopsys Detect
OWASP dependency check

Container scanning
Qualys scanning
Snyk scanning
Trivy scanner

Scanning for secrets
CredScan
gitLeaks

Automating scans
SonarCloud in a build pipeline  
configuring OWASP zap scan in a release pipeline




Designing Governance Enforcement
Azure policies
container scanning
azure container registry tasks
break-the-glass strategy for responding to security incidents  
hot-fix strategy
policy compliance check
azure policy
governance requirements
enforced and audited at the cloudAPI
shift to self-service in cloud
deny, audit, remidiate
azure policy for AKS
azure security center integration
azure defender  for container registries


Designing Build automation
examination on content(static) and performance(dynamic)
SonaQube
PMD Programming Mistake Detector
dependency management
SCA Software Composition Analysis
WhiteSource Bolt
BlackDuck
Snyk
dynamic analysis




Understanding Testing Strategies
multiple dimesions of quality
testing measurment
performance measure
load testing
performance under load
maximum load
load testing production
blue green deployment
Apache JMeter
Robustness
Fuzz testing
OneFuzz
Availability Measure
Postman
Intergration testing
Chaos testing
Chaos Monkey
Simian Army

service hooks
service connections



Designing a Package Management Strategy
software reuse
package source
package management tool
WebPack, Parcel, Yarn
NPM
Maven
NuGet
RubyGems
PyPI

Upstream Proxy
Azure artifacts
Github packages
managing software supply chain
Dependabot, Nukeeper, GreenKeeper

Versioning strategy
dependency hell
semantic versioning
MAJOR.MINOR.PATCH-QUALITY
1.2.3-beta1
GitVersion tool
Gitflow branching strategy




Application infrastructure management strategy
configuration management in Azure
feature flags
one configuration, multiple environments
azure continous assurance



Implementing, Maintaining, and Standardizing Build Strategies
planning your agents
self hosted agents
batching and branching
build triggers
push, pull request, pipeline, scheduled trigger

dependency packaging
dependency equiped container



Developing deployment scripts and templates
IaC
Database deployments
configuration management
release stages and triggers
deployment gates
Azure state configuration
DSC Desired State Configuration
App Center Distribution Groups
Multi region deployments with Azure Traffic Manager




Implementing Orchestration Automation Solutions
CI CD
unit test
platform test
deploy to staging environment
acceptance tests
deploy to production environment




Plannin Deployment Environment Strategies
Blue-Green, Rolling, Canary
Azure Application Gateway
Schema-on-read
Reconcile the existing state with the changes
Blow away whats there and replace it with the changes
Create a brand-new environment and replace the old one
Snowflake server
Immutable server
Hotfixes
Release branch
Gitflow
ReleaseFlow

Understanding state configuration tools
Idempotence
Mitigating Configuration drift




Developing a Modern Source Control Strategy








Exam DP-203: Data Engineering on Microsoft Azure
Design and Implement Data Storage (40-45%)
Design a data storage structure
 design an Azure Data Lake solution
 recommend file types for storage
 recommend file types for analytical queries
 design for efficient querying
 design for data pruning
 design a folder structure that represents the levels of data transformation
 design a distribution strategy
 design a data archiving solution
Design a partition strategy
 design a partition strategy for files
 design a partition strategy for analytical workloads
 design a partition strategy for efficiency/performance
 design a partition strategy for Azure Synapse Analytics
 identify when partitioning is needed in Azure Data Lake Storage Gen2
Design the serving layer
 design star schemas
 design slowly changing dimensions
 design a dimensional hierarchy
 design a solution for temporal data
 design for incremental loading
 design analytical stores
 design metastores in Azure Synapse Analytics and Azure Databricks
Implement physical data storage structures
 implement compression
 implement partitioning
 implement sharding
 implement different table geometries with Azure Synapse Analytics pools
 implement data redundancy
 implement distributions
 implement data archiving
Implement logical data structures
 build a temporal data solution
 build a slowly changing dimension
 build a logical folder structure
 build external tables
 implement file and folder structures for efficient querying and data pruning
Implement the serving layer
 deliver data in a relational star schema
 deliver data in Parquet files
 maintain metadata
 implement a dimensional hierarchy
Design and Develop Data Processing (25-30%)
Ingest and transform data
 transform data by using Apache Spark
 transform data by using Transact-SQL
 transform data by using Data Factory
 transform data by using Azure Synapse Pipelines
 transform data by using Stream Analytics
 cleanse data
 split data
 shred JSON
 encode and decode data
 configure error handling for the transformation
 normalize and denormalize values
 transform data by using Scala
 perform data exploratory analysis
Design and develop a batch processing solution
 develop batch processing solutions by using Data Factory, Data Lake, Spark, Azure
Synapse Pipelines, PolyBase, and Azure Databricks
 create data pipelines
 design and implement incremental data loads
 design and develop slowly changing dimensions
 handle security and compliance requirements
 scale resources
 configure the batch size
 design and create tests for data pipelines
 integrate Jupyter/IPython notebooks into a data pipeline
 handle duplicate data
 handle missing data
 handle late-arriving data
 upsert data
 regress to a previous state
 design and configure exception handling
 configure batch retention
 design a batch processing solution
 debug Spark jobs by using the Spark UI
Design and develop a stream processing solution
 develop a stream processing solution by using Stream Analytics, Azure Databricks, and
Azure Event Hubs
 process data by using Spark structured streaming
 monitor for performance and functional regressions
 design and create windowed aggregates
 handle schema drift
 process time series data
 process across partitions
 process within one partition
 configure checkpoints/watermarking during processing
 scale resources
 design and create tests for data pipelines
 optimize pipelines for analytical or transactional purposes
 handle interruptions
 design and configure exception handling
 upsert data
 replay archived stream data
 design a stream processing solution
Manage batches and pipelines
 trigger batches
 handle failed batch loads
 validate batch loads
 manage data pipelines in Data Factory/Synapse Pipelines
 schedule data pipelines in Data Factory/Synapse Pipelines
 implement version control for pipeline artifacts
 manage Spark jobs in a pipeline
Design and Implement Data Security (10-15%)
Design security for data policies and standards
 design data encryption for data at rest and in transit
 design a data auditing strategy
 design a data masking strategy
 design for data privacy
 design a data retention policy
 design to purge data based on business requirements
 design Azure role-based access control (Azure RBAC) and POSIX-like Access Control List
(ACL) for Data Lake Storage Gen2
 design row-level and column-level security
Implement data security
 implement data masking
 encrypt data at rest and in motion
 implement row-level and column-level security
 implement Azure RBAC
 implement POSIX-like ACLs for Data Lake Storage Gen2
 implement a data retention policy
 implement a data auditing strategy
 manage identities, keys, and secrets across different data platform technologies
 implement secure endpoints (private and public)
 implement resource tokens in Azure Databricks
 load a DataFrame with sensitive information
 write encrypted data to tables or Parquet files
 manage sensitive information
Monitor and Optimize Data Storage and Data Processing (10-15%)
Monitor data storage and data processing
 implement logging used by Azure Monitor
 configure monitoring services
 measure performance of data movement
 monitor and update statistics about data across a system
 monitor data pipeline performance
 measure query performance
 monitor cluster performance
 understand custom logging options
 schedule and monitor pipeline tests
 interpret Azure Monitor metrics and logs
 interpret a Spark directed acyclic graph (DAG)
Optimize and troubleshoot data storage and data processing
 compact small files
 rewrite user-defined functions (UDFs)
 handle skew in data
 handle data spill
 tune shuffle partitions
 find shuffling in a pipeline
 optimize resource management
 tune queries by using indexers
 tune queries by using cache
 optimize pipelines for analytical or transactional purposes
 optimize pipeline for descriptive versus analytical workloads
 troubleshoot a failed spark job
 troubleshoot a failed pipeline run









Exam DP-203: Data Engineering on Microsoft Azure
Design and Implement Data Storage (40-45%)
Design a data storage structure








design an Azure Data Lake solution
recommend file types for storage
recommend file types for analytical queries
design for efficient querying
design for data pruning
design a folder structure that represents the levels of data transformation
design a distribution strategy
design a data archiving solution
Design a partition strategy





design a partition strategy for files
design a partition strategy for analytical workloads
design a partition strategy for efficiency/performance
design a partition strategy for Azure Synapse Analytics
identify when partitioning is needed in Azure Data Lake Storage Gen2
Design the serving layer







design star schemas
design slowly changing dimensions
design a dimensional hierarchy
design a solution for temporal data
design for incremental loading
design analytical stores
design metastores in Azure Synapse Analytics and Azure Databricks
Implement physical data storage structures






implement compression
implement partitioning
implement sharding
implement different table geometries with Azure Synapse Analytics pools
implement data redundancy
implement distributions
implement data archiving
Implement logical data structures





build a temporal data solution
build a slowly changing dimension
build a logical folder structure
build external tables
implement file and folder structures for efficient querying and data pruning
Implement the serving layer




deliver data in a relational star schema
deliver data in Parquet files
maintain metadata
implement a dimensional hierarchy
Design and Develop Data Processing (25-30%)
Ingest and transform data













transform data by using Apache Spark
transform data by using Transact-SQL
transform data by using Data Factory
transform data by using Azure Synapse Pipelines
transform data by using Stream Analytics
cleanse data
split data
shred JSON
encode and decode data
configure error handling for the transformation
normalize and denormalize values
transform data by using Scala
perform data exploratory analysis
Design and develop a batch processing solution develop batch processing solutions by using Data Factory, Data Lake, Spark, Azure

















Synapse Pipelines, PolyBase, and Azure Databricks
create data pipelines
design and implement incremental data loads
design and develop slowly changing dimensions
handle security and compliance requirements
scale resources
configure the batch size
design and create tests for data pipelines
integrate Jupyter/IPython notebooks into a data pipeline
handle duplicate data
handle missing data
handle late-arriving data
upsert data
regress to a previous state
design and configure exception handling
configure batch retention
design a batch processing solution
debug Spark jobs by using the Spark UI
Design and develop a stream processing solution
 develop a stream processing solution by using Stream Analytics, Azure Databricks, and
















Azure Event Hubs
process data by using Spark structured streaming
monitor for performance and functional regressions
design and create windowed aggregates
handle schema drift
process time series data
process across partitions
process within one partition
configure checkpoints/watermarking during processing
scale resources
design and create tests for data pipelines
optimize pipelines for analytical or transactional purposes
handle interruptions
design and configure exception handling
upsert data
replay archived stream data
design a stream processing solution
Manage batches and pipelines
 trigger batches





handle failed batch loads
validate batch loads
manage data pipelines in Data Factory/Synapse Pipelines
schedule data pipelines in Data Factory/Synapse Pipelines
implement version control for pipeline artifacts
manage Spark jobs in a pipeline
Design and Implement Data Security (10-15%)
Design security for data policies and standards
design data encryption for data at rest and in transit
design a data auditing strategy
design a data masking strategy
design for data privacy
design a data retention policy
design to purge data based on business requirements
design Azure role-based access control (Azure RBAC) and POSIX-like Access Control List
(ACL) for Data Lake Storage Gen2
 design row-level and column-level security







Implement data security













implement data masking
encrypt data at rest and in motion
implement row-level and column-level security
implement Azure RBAC
implement POSIX-like ACLs for Data Lake Storage Gen2
implement a data retention policy
implement a data auditing strategy
manage identities, keys, and secrets across different data platform technologies
implement secure endpoints (private and public)
implement resource tokens in Azure Databricks
load a DataFrame with sensitive information
write encrypted data to tables or Parquet files
manage sensitive information
Monitor and Optimize Data Storage and Data Processing (10-15%)
Monitor data storage and data processing
 implement logging used by Azure Monitor
 configure monitoring services
 measure performance of data movement







monitor and update statistics about data across a system
monitor data pipeline performance
measure query performance
monitor cluster performance
understand custom logging options
schedule and monitor pipeline tests
interpret Azure Monitor metrics and logs
interpret a Spark directed acyclic graph (DAG)
Optimize and troubleshoot data storage and data processing













compact small files
rewrite user-defined functions (UDFs)
handle skew in data
handle data spill
tune shuffle partitions
find shuffling in a pipeline
optimize resource management
tune queries by using indexers
tune queries by using cache
optimize pipelines for analytical or transactional purposes
optimize pipeline for descriptive versus analytical workloads
troubleshoot a failed spark job
troubleshoot a failed pipeline run










Data Storage
Data Processing
Visualizing your data


Data Lake is used for storing large amounts of data in its native, raw format  
- optimized for storing terabytes and petabytes of data  
- data could be from a variety of data sources  
- data could be of various formats structured, semi-structured, and unstructured data  
- working with large data sets  
- here data arrrives in large volumes  
- the data arrives at a fast rate  



Azure Data Lake Storage Gen2  
- this service is built on top of Azure Blob storage  
- gives ability to host an enterprise data lake on Azure  
- you get features of hierarchical namespace on top of Azure blob storage  
- helps to organize objects/files into a hierarchy of directories for efficient data access  



Redundancy  




SQL commands  

SQL Datawarehouse  

the database engine will process the operation and return the result to the user  

select * from Sales.Product  
select productId,Name,Prize from Sales.Product  
select count(*) as Count from Sales.Product  

select * from Sales.Product where productId=80
select * from Sales.Product where productId>80
select * from Sales.Product where productId between 80 and 100

select * from Sales.Product where productId from Sales.Product where Name like '%brush%'



when we use WHERE caluse in sql queries we should be using something called Partitions  
in the datawarehouse to ensure that we increase the efficiency of queries that are doing
filtering  


select * from Sales.Product order by Prize  
select * from Sales.Product order by Prize Desc   


aggregate functions  


selct count(ProductId) from Sales.Product where Name Like '%Gold%'  
selct max(ProductId) from Sales.Product where Name Like '%Gold%'  
selct min(ProductId) from Sales.Product where Name Like '%Gold%'  
selct sum(ProductId) from Sales.Product where Name Like '%Gold%'  
selct avg(ProductId) from Sales.Product where Name Like '%Gold%'  


GROUP By  is used to group rows into summary rows  
and can also be used along with the 
aggregation functions of (COUNT, MAX, MIN, SUM, AVG)  

select count(ProductId) from Sales.Product group by Color  
select count(ProductId) as 'Product Id Count' from Sales.Product group by Color  
select count(ProductId) as 'Product Id Count',Color from Sales.Product group by Color  

select count(ProductId) as 'Product Id Count',Color from Sales.Product where Color IS NOT NULL group by Color  



If you want to increase the efficiency of group by clause, we will use different
types of tables    Hash-distributed tables  and  Replicated distribution tables  



aggregation functions of (COUNT, MAX, MIN, SUM, AVG)  cannot be used along with WHERE clause 
in that cases we have HAVING clause in SQL  

select count(ProductId) as 'Product Id Count',Color from Sales.Product where Color IS NOT NULL group by Color HAVING count(Color)>10  

Primary and Foreign Key

Based on relationships and coloumns we can construct something known as dimension tables 
which will be used in something known as a star schema  


create table Orders (
    OrderId varchar(100) Not Null,
    CourseId varchar(100),
    CustomerId varchar(100),
    Discountperscent int,
    Foreign Key (CustomerId) reference Customer(CustomerId),
    Foreign Key (CourseId) reference Course(CourseId) );

Insert into Orders(OrderId,CourseId,Discountperscent) values ('O1','C1',90)


perform join on two tables

select Sales.Product.ProductId,Price,OrderQty
from Sales.Product join Sales.SalesOrderDetail
on Sales.Product.ProductId=Sales.SalesOrderDetail.ProductID


Azure synapse warehouse do not have foreign keys 





Azure Synaps Analytics  

dedicated sql pool
dimesion and fact tables  

hash distributed tables 
replicated tables 
round robin tables 


transactional data store
online analytical processing system

example udemy
how many student are registering per day
which countries have max no of students 

visualization tools such as powerBI


you can use pipelines for data integration
which allows u to perfome ETL/ELT in bringing data into data warehouse

you can use spark to process your data 


Azure Synapase Workplace
Analytic pools
- SQL pools
- Apache Spark pools  


2 available compute options
Serverless SQL pool
SQL pool


DTU  Database Transaction Unit
DWU  Data Warehousing Unit



External tables 

-Here the data lies in another source and we just defined the table structure in Azure Synapse
-When we query for data within the table, the data is queried from the external source
-An external table can point to data that is located in Hadoop, Azure Blob storage or Azure Data Lake Storage

Azure Syanapse :  serverles pool

PolyBase is the feature used to access data in external tables  

the purpose of external table is your table definition will be in Azure synapse
and your data will be located somewhere else
this is usefull when you dont want to bring the data on the server itself
While in the case of an sql server the table definition and data is on sql server itself

Steps
step1: authorization to use the data lake storage account
step2: define the format of external file we are going to work with - Parquet, CSV
step3: create the external table



dedicated SQL pool


Data Cleansing  

process of finding and correcting/removing corrupt or inaccurate records in a record set
what to do with rows that have columns with NULL values
Sometimes values may not be in the defined range like the age of person
Formating dates, different systems might store dates in different formats  




Data Cleansing Cycle 

Import Data
Merge Data sets
Rebuild Missing Data
Standardize
Normalize
De-Duplicate
Verify and Encrich
Export Data


Data Science Process

Business Understanding
Data Understanding
Data Preparation
Model Building
Evaluating Model
Model Deployment




	




# load data from log.csv file

copy into logdata from 'https://datalake2000.blob.core.windows.net/data/raw/log.csv'
with
(
firstrow=2
)

select * from [logdata]

# delete the existing data from the table

delete from [logdata]

# load data from praquet file

create table [logdata]
(
  [Id] [int] ,
  [Correlationid] [varchar](200) ,
  [Operationname] [varchar](200) ,
  [Time] [datetime] ,
  [Subscription] [varchar](200)
)


copy into [logdata] from 'https://datalake200.blob.core.windows.net/data/raw/parquet/*.parquet'
with
(
FILE_TYPE='PARQUET',
credential=(identity='Shared Access Signature', SECRET='fadfafadfaf'
)

select * from [logdata]




Pausing dedicated sql pool to not get charged
If you delete the pool all data will be lost


Loading data using PolyBase



# creating an external target

create master key encryption by password = 'passswor';

# to see existing database scoped credentials

select * from sys.database_scoped_credentials


# to see external file formats

select * from sys.external_file_formats

create external file format parquetfile
with (
   format_type = PARQUET,
   data_compression = 'org.apache.hadoop.io.compress.SnappyCodec'
);



# create the external table as the admin user

create external table [logdata_external]
(
 [Id] [int] ,
    [Correlationid] [varchar](200) ,
    [Operationname] [varchar](200) ,
    [Status] [varchar](100) ,
    [Time] [datetime] ,
)
with (
 location = '/raw/parquet/',
    data_source = log_data,
    file_format = parquetfile
)


# to create a normal table by selecting all data

create table [logdata]
with
(
distribution = round_robin,
clustered index (id)
)
select * 
from [logdata_external];





SQL Data Warehouse


# Designing a Data Warehouse

- patterns in building tables in a data warehouse
- Star schema or SnowFlake schema
- database Normalization
- OLTP workloads ( transactional workloads )


Fact Tables
- measurments or metrics that correspond to facts
- example: sales table - this records all the sales that have been made
- sales data are facts that sales have actually been made

Dimension Tables
- this helps to provide some sort of context to the facts that are presented
- example: what products were sold
- who are the customers who bought the products


Star Schema
- fact table will be in the middle
- dimension tables supporting the facts will be there in dimension tables around the fact table
- fact table will contain primary keys used in the dimension table



Why we need to build fact and dimension tables in the first place?
Its very useful in using Power BI for star schema




Understanding Azure Synapse Architecture


Dedicated sql Pool - data warehouse

available table types in dedicatd sql pool
- hash-distributed tables
- replicated tables
- round-robin distributed tables






Windowing functions
- allows to apply a mathematical eqn on a set of data that is defined within a window
- you can split the rows of data into different sets and apply an aggregate to the data in each set
- when using windowing functions with sql pools, you will use the OVER clause
- clause determines the partitioning and ordering of a rowset before the associated window function is applied


Surrogate keys


Slowly changing dimensions




Snowflake schema




Pratitions in Azure synapse

Table partitions
- helps to divide data into smaller groups of data
- normally data is partitioned by dates
- helps in filtering data when using the WHERE clause in queries
- here the engine can then just process the data in the partitions
  based on the condition mentioned in the WHERE clause


Try not to create too many partitions
The data will be distributed across distributions and partitions
For optimal compression and performance of clustered columnstore tables,
a minimum of 1 million rows per distribution and partition is needed


Indexes

Normally database system have a feature available for table known as indexes
Indexes help reduce time taken to search table for data based on queries that are fired

Clustered Columnstore indexes
- by default for Azure Synapse SQL pool table, ther is a clustered cloumnar store index that gets created
- this sort of index provides the highes level of data compression and best overall query performance
- this cant be created if there are columns that are of the type varchar(max), nvarchar(max) or varbinary(max)



Heap tables
- used when temporarily loading data into a table for staging purpose
- are faster to load and reads can be taken from the cache

Clustered indexes
- clustered index can be created on just a specific column of a table
- used when there are a few lookup making use of very specific column

non Clustered indexes
- if you want to improve the filtering on other columns, you can create a 
  non clustered index for the other columns
- but this adds to table space and processing time to load on table



Data Warehouse Architecture
- data warehouse can pull data from the Data Lake
- you can use this data lake to store files in JSON, Parquet, CSV format
- then you can use this data along with data from Structured data stores
  and create tables in a data warehouse


Serverless SQL pool
Dedicated SQL pool
Spark Pool



Azure Data Factory
- ETL tool
- batch processing needs
- copy activity
- mapping data flow
- create data-driven workflows
- workflows help orchestrate data movement
- help to transform the data



Extract, transform and load process ETL
- transformation engine
- extract data from various data sources
- filtering, sorting, aggregation, joining data, cleaning data

Tools
- Azure Data Factory
- SQL server ingtegration service


ELT
- load and transform actions happen on the target itself
- here thers no need of a seperate transformation engine
- target system must be powerful enough to do the transformation



Azure Data Factory process
- connect to required data source
- ingest data from the source
- transform data in pipeline
- publish data onto a destination

Azure Data Factory components
- linked service: enables to ingest data from data source
                  create required compute resources to take data from data source
- datasets: represents data structue within data store thats being 
            being referenced by the linked service object
- activity: contains the actual transformation logic, you can also have simple
            copy activities to copy data from source to destination



Azure pipelines
- logical grouping of activities



Git for Version Control of pipelines in Azure Data Factory





Data Processing Azure Event Hubs and Stream Analytics

Batch Processing
- large set of semi-structured files processed into structured files 
  that can be used for future Analysis needs
- Web Server logs copied to (Azure Data lake Gen2) storage accounts over the data
  then a batch process (Spark) happens in night that process the data and send to
  Analytical dat store (Azure Synapse) for daily reporting (Power BI) purposes
  and the orchestration is handled by (Azure Data Factory)  


Real Time Processing
- data captured in real-time and processed with minimal latency to generate real-time reports
- processing of data need to be done fast so that it does not block incoming stream of data
- platform should be available to ingest large amounts of data at a fast rate
- Real-time message Ingestion (Apache Kafka, Azure Event Hubs)
  Data Storage (Azure Blob Storage, Azure Data Lake Store)
  Stream Processing (Azure Stream Analytics, Storm, Spark Streaming)
  Analytical data store (Azure Synapse, Spark, Hive, HBase)
  Reporting (Power BI)




Azure Event Hubs Capture  

Azure Event Hubs  
Azure Stream Analytics  
Azure Data Lake  
Azure Data Factory  





Scala
REPL is a command line utility that can be used for running scala commands  
REPL: Read, Evaluate, Print, Loop



Jupyter Notebook
we need to run the commands in notebook in spark pool and azure databricks
you can run python, scala and scala commands in notebook
and the notebook commands can target the spark cluster


Azure Synapse - Spark pool

Spark is used as a parallel processing framework
for big-data analytical applications

driver nodes
executor nodes





Databricks

- makes use of apache spark to provide a Unified Analytics platform
- the entire environment can be provisioned with just a few clicks  
- will create the undelying compute infra for you
- has its own underlying file system which is an abstraction of 
  underlying storage layer  
- it will install Spark and other ML libraries  
- provides a workspace


Azure Databricks
Cluster

Worker nodes
- distributes the task to worker nodes
Driver node
- nodes that actually perform the underlying tasks  


Interactive cluster
- analyze data with interactive notebooks

Job cluster
- runs a job on the cluster
- when job is complete cluster will be terminated  



Data Security
- Azure Data Factory already encrypts data at rest which also includes
  entity definitions and any data thats cached
- Encryption is carried out with Microsoft-managed keys
- Aure data factory encryption
- customer managed keys
- azure dedicated sql pool transparent data encryption
- Azure synapse data masking
- Azure synapse auditing
- data discovery and classification
- Azure AD authentication setting admin and user
- Azure Synapse Row & Column level security
- Azure Data Lake Role Based Access Control
- Access Control Lists
- External table authorization via Managed Identity
- External table authorization via AD Authentication
- Azure Synapse Firewall
- Azure Data Lake Virtual Network Service Endpoint
- Azure Data Lake Managed Identity Data Factory  



Monitor and Optimize Data Storage and Processing  
- structuring files in your data lake
- well egineered data lake structure
- different zones can be mapped to separate containers  
- Raw Zone, Filtered Zone, Curated Zone  
- Azure monitor
- result set caching
- system views
- workload management
- retention points
- monitoring
- alerts and mertics
- annotations
- integration runtime
- pipeline failures
- high availability
- Azure Stream Analytics metrics
- streaming units
- partitions
- diagnostics



[https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-overview](https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-overview)  
[https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/massively-parallel-processing-mpp-architecture](https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/massively-parallel-processing-mpp-architecture)  




[https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/design-guidance-for-replicated-tables](https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/design-guidance-for-replicated-tables)  
[https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-distribute](https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-distribute)  




[https://docs.microsoft.com/en-us/stream-analytics-query/stream-analytics-query-language-reference](https://docs.microsoft.com/en-us/stream-analytics-query/stream-analytics-query-language-reference)  








[https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-window-functions](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-window-functions)  



[https://docs.microsoft.com/en-us/stream-analytics-query/windowing-azure-stream-analytics](https://docs.microsoft.com/en-us/stream-analytics-query/windowing-azure-stream-analytics)  
[https://docs.microsoft.com/en-us/stream-analytics-query/session-window-azure-stream-analytics](https://docs.microsoft.com/en-us/stream-analytics-query/session-window-azure-stream-analytics)  
[https://docs.microsoft.com/en-us/stream-analytics-query/hopping-window-azure-stream-analytics](https://docs.microsoft.com/en-us/stream-analytics-query/hopping-window-azure-stream-analytics)  
[https://docs.microsoft.com/en-us/stream-analytics-query/snapshot-window-azure-stream-analytics](https://docs.microsoft.com/en-us/stream-analytics-query/snapshot-window-azure-stream-analytics)  
[https://docs.microsoft.com/en-us/stream-analytics-query/tumbling-window-azure-stream-analytics](https://docs.microsoft.com/en-us/stream-analytics-query/tumbling-window-azure-stream-analytics)  
[https://docs.microsoft.com/en-us/stream-analytics-query/sliding-window-azure-stream-analytics](https://docs.microsoft.com/en-us/stream-analytics-query/sliding-window-azure-stream-analytics)  



[https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-streaming-unit-consumption](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-streaming-unit-consumption)  
[https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-parallelization](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-parallelization)  
[https://docs.microsoft.com/en-us/azure/stream-analytics/repartition](https://docs.microsoft.com/en-us/azure/stream-analytics/repartition)  
[https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-scale-jobs](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-scale-jobs)  





[https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/cheat-sheet](https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/cheat-sheet)  



[https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-partition](https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-partition)  



[https://docs.microsoft.com/en-us/azure/synapse-analytics/sql/develop-tables-external-tables?tabs=hadoop](https://docs.microsoft.com/en-us/azure/synapse-analytics/sql/develop-tables-external-tables?tabs=hadoop)  



[https://docs.microsoft.com/en-us/azure/data-factory/concepts-integration-runtime](https://docs.microsoft.com/en-us/azure/data-factory/concepts-integration-runtime)  



[https://docs.microsoft.com/en-us/azure/data-factory/concepts-data-flow-overview](https://docs.microsoft.com/en-us/azure/data-factory/concepts-data-flow-overview)  


[https://docs.microsoft.com/en-us/azure/data-factory/create-azure-integration-runtime](https://docs.microsoft.com/en-us/azure/data-factory/create-azure-integration-runtime)  
[https://docs.microsoft.com/en-us/azure/data-factory/create-self-hosted-integration-runtime](https://docs.microsoft.com/en-us/azure/data-factory/create-self-hosted-integration-runtime)  
[https://docs.microsoft.com/en-us/azure/data-factory/create-azure-ssis-integration-runtime](https://docs.microsoft.com/en-us/azure/data-factory/create-azure-ssis-integration-runtime)  






[https://docs.microsoft.com/en-us/azure/data-factory/how-to-create-schedule-trigger?tabs=data-factory](https://docs.microsoft.com/en-us/azure/data-factory/how-to-create-schedule-trigger?tabs=data-factory)  
[https://docs.microsoft.com/en-us/azure/data-factory/how-to-create-tumbling-window-trigger](https://docs.microsoft.com/en-us/azure/data-factory/how-to-create-tumbling-window-trigger)  
[https://docs.microsoft.com/en-us/azure/data-factory/how-to-create-event-trigger?tabs=data-factory](https://docs.microsoft.com/en-us/azure/data-factory/how-to-create-event-trigger?tabs=data-factory)  






[https://docs.microsoft.com/en-us/sql/relational-databases/security/row-level-security?view=sql-server-ver16](https://docs.microsoft.com/en-us/sql/relational-databases/security/row-level-security?view=sql-server-ver16)  
[https://docs.microsoft.com/en-us/sql/relational-databases/security/dynamic-data-masking?view=sql-server-ver16](https://docs.microsoft.com/en-us/sql/relational-databases/security/dynamic-data-masking?view=sql-server-ver16)  
[https://docs.microsoft.com/en-us/sql/relational-databases/security/sql-server-certificates-and-asymmetric-keys?view=sql-server-ver16](https://docs.microsoft.com/en-us/sql/relational-databases/security/sql-server-certificates-and-asymmetric-keys?view=sql-server-ver16)  
[https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/column-level-security](https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/column-level-security)  





[https://docs.microsoft.com/en-us/learn/modules/design-multidimensional-schema-to-optimize-analytical-workloads/](https://docs.microsoft.com/en-us/learn/modules/design-multidimensional-schema-to-optimize-analytical-workloads/)  
[https://docs.microsoft.com/en-us/learn/modules/populate-slowly-changing-dimensions-azure-synapse-analytics-pipelines/](https://docs.microsoft.com/en-us/learn/modules/populate-slowly-changing-dimensions-azure-synapse-analytics-pipelines/)  




[https://docs.microsoft.com/en-us/azure/architecture/data-guide/relational-data/data-warehousing](https://docs.microsoft.com/en-us/azure/architecture/data-guide/relational-data/data-warehousing)  

[https://docs.microsoft.com/en-us/power-bi/guidance/star-schema](https://docs.microsoft.com/en-us/power-bi/guidance/star-schema)  




[https://medium.com/@datacouch/star-and-snowflake-schema-in-azure-sql-7b68113b63fb](https://medium.com/@datacouch/star-and-snowflake-schema-in-azure-sql-7b68113b63fb)  



[https://docs.microsoft.com/en-us/azure/data-explorer/kusto/concepts/fact-and-dimension-tables](https://docs.microsoft.com/en-us/azure/data-explorer/kusto/concepts/fact-and-dimension-tables)  
[https://www.sqlshack.com/implementing-slowly-changing-dimensions-scds-in-data-warehouses/](https://www.sqlshack.com/implementing-slowly-changing-dimensions-scds-in-data-warehouses/)  



[https://docs.microsoft.com/en-us/sql/t-sql/language-elements/case-transact-sql?view=sql-server-ver16](https://docs.microsoft.com/en-us/sql/t-sql/language-elements/case-transact-sql?view=sql-server-ver16)  


[https://docs.microsoft.com/en-us/azure/stream-analytics/repartition](https://docs.microsoft.com/en-us/azure/stream-analytics/repartition)  


[https://docs.microsoft.com/en-us/azure/databricks/clusters/clusters-manage](https://docs.microsoft.com/en-us/azure/databricks/clusters/clusters-manage)  



data sources    ->   data storage   ->  batch processing   ->  anlytical datastore  ->  analytics

data sources    -> real-time message ingestion   ->   stream processing     ->     analytics

                    -------   Orchestration    ---------


key selection criteria
design and implement star schema
slowly changing dimesion types
dealing with dimensional hierarchies


create and monitor data pipelines for a batch processing solution  






Process Big Data:    Lambda and Kappa Architectures  


data may need real time processing  

anomaly detection  
cruises at sea  


lambda architecture 
- duplicates processing logic in both hot and cold paths
- has an accurate cold path and less accurate hot path



kappa architecture
- needs that every report and metric is incremental
- for real-time processing


[https://docs.microsoft.com/en-us/azure/architecture/data-guide/big-data/](https://docs.microsoft.com/en-us/azure/architecture/data-guide/big-data/)  



data storage:   azure sql database, azure cosmosDB, Azure data lake storage gen 2  

analytical data store:  azure synapse analytics,  spark SQL,  HBase  

orchestration:   azure data factory

batch processing engine:   azure synapse analytics, azure data lake analytics, azure databricks, HDinsight  
visualisation engine:   power BI





Data factory components
- data set
- activity
- pipeline
- linked service


slowly changing dimensions
- SCD is the most commonly used advanced dimensional
  technique used in dimensional data warehouse  
- SCD is a column that need to change the allowed values
  due to a refactoring need in the business


copy the newst data
- implement a data factory pipeline that
  incrementally loads data from sql 
  database into blob storage
- implement a data factory pipeline that
  handles exceptions 



incremental loading strategy
- get last watermark
- get last watermark again
- delta load data b/w 2 watermarks from 
  source table to destination 
- update watermarks for delta data
  loading next time





Stream processing solutions  
- event hubs
- stream analytics
- databricks
- synapse analytics  




Design a data masking strategy  
Design a data retention policy
Design a data encryption strategy
Design a data auditing strategy




Designing a stream processing pipeline
- data producers
- message ingestion
- stream processing
- analytical data store
- analysis and reporting




Handling time with window functions
- tumbling
- hopping
- sliding
- session
- snapshot



Stream Processing Real-life Example

Transportation: check areas with high traffic volumes and suggest alternatives
Health-care: monitor patients in critical condition every few seconds  
Trading: oversee and process in real-time the financial transactions  
Polling: analyze and interpret on the spot the response of the pllsters
Wheather Research: record the temparature in serveral locations every few 
		   seconds to create accurate weather reports  




Process time series data with window functions  

working with temporal functions that create non-overlapping windows


example:
you receive data from a device that monitors a persions pulse

requirements:
- no of values over 130 recorded every 10 seconds
- no of values over 130 that appeared more than 5 times in the last 30 seconds
- no of abnormal values from different sensors, occuring at the same time


apply functions that group data based on time 

Temporal functions (window functions)  



non overlapping windows:  tumbling, session, snapshot

overlapping windows:   hopping, sliding  




tumbling window
- splits data stream into distinct time segments and performs a
  function against them
- {TUMBLINGWINDOW | TUMBLING} ( time unit, window size )
- how many events are recorded every 10 seconds
  select count(*) as Events from Source timestamp by CreatedAt group by tumblingwindow(second, 10)
- fixed size
- non overlapping
- contiguous
- an event cannot belong to more than one window


session window
- groups or  aggregates events that arrive at similar times
- {SESSIONWINDOW | SESSION} ( time unit, timeout size, max duration size )
- how many events occur within 5 seconds of each other
  select count(*) as Events from Source timestamp by CreatedAt group by sessionwindow(second, 5, 10)
- filters out periods with no data
- session window begins when the first event occurs
- if another event appears within the timeout frame, the window extends
- if no event appears within the timeout frame, the window closes at timout


snapshot window
- groups events that have the same timestamp
- does not require a specific window function
- can apply a snapshot window by adding System.Timestamp() in the Group By clause
  select count(*) as Events from Source timestamp by CreatedAt group by System.Timestamp()



hoping window
- hops forward in time by a fixed period
  {HOPPINGWINDOW | HOPPING} ( time unit, window size, hop size )
- every 5 seconds, calculate the no of events recorded in the last 10 seconds
  select count(*) as Events from Source timestamp by CreatedAt group by hoppingwindow(second, 10, 5)
- hop size tells how much the window moves forward relative to the previous one
- windows can overlap
- windows can be emitted more often than the window size
- events can belong to more than one window
- if hop size = window size,  hopping = tumbling



sliding window
- doesn't aggregate values after a fixed period
  {SLIDINGWINDOW | SLIDING} (time unit, window size)
- creates a new output every time an event is recorded or when an existing event falls out of the time window
- no of events recorded in the last 10 seconds
  select count(*) as Events from Source timestamp by CreatedAt group by slidingwindow(second, 10)
- intervals are not fixed
- outputs are produced only when the content of the window changes
- a window must have at least one event
- events can belong to more than one window




Example:  real time processing solution for
  every 10 seconds retrieve the products analyzed by the customers of an online store in the
  last 60 seconds, generate outputs even if no events occurred, an event can be part of multiple
  windows
  can be solved usin hopping window


Example:  real time processing solution for
   to count the no of orders received in the last 60 seconds, if no orders were registered
   the query should not generate a window
   use sliding window




https://www.geeksforgeeks.org/difference-between-clustered-and-non-clustered-index/


https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-tables-partition






```





# Links  

[https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy](https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy)  
[https://docs.microsoft.com/en-us/azure/load-balancer/skus](https://docs.microsoft.com/en-us/azure/load-balancer/skus)  
[https://www.microsoft.com/en-in/security/business/identity-access/azure-active-directory-pricing](https://www.microsoft.com/en-in/security/business/identity-access/azure-active-directory-pricing)  
[https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction](https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction)  
[https://docs.microsoft.com/en-us/azure/virtual-network/concepts-and-best-practices](https://docs.microsoft.com/en-us/azure/virtual-network/concepts-and-best-practices)  
[https://docs.microsoft.com/en-us/azure/storage/files/storage-files-introduction](https://docs.microsoft.com/en-us/azure/storage/files/storage-files-introduction)  
[https://docs.microsoft.com/en-us/azure/logic-apps/logic-apps-overview](https://docs.microsoft.com/en-us/azure/logic-apps/logic-apps-overview)  
[https://docs.microsoft.com/en-us/azure/governance/blueprints/overview](https://docs.microsoft.com/en-us/azure/governance/blueprints/overview)  
[https://azure.microsoft.com/en-in/support/plans/](https://azure.microsoft.com/en-in/support/plans/)  
[https://azure.microsoft.com/en-in/free/](https://azure.microsoft.com/en-in/free/)  
[https://www.dotnettricks.com/learn/azure/what-is-vm-scale-set-availability-zone-availability-sets-and-regions-in-azure](https://www.dotnettricks.com/learn/azure/what-is-vm-scale-set-availability-zone-availability-sets-and-regions-in-azure)  
[https://docs.microsoft.com/en-us/cli/azure/](https://docs.microsoft.com/en-us/cli/azure/)  
[https://docs.microsoft.com/en-us/cli/azure/reference-index?view=azure-cli-latest](https://docs.microsoft.com/en-us/cli/azure/reference-index?view=azure-cli-latest)  
[https://docs.microsoft.com/en-us/azure/virtual-machines/linux/use-remote-desktop?tabs=azure-cli](https://docs.microsoft.com/en-us/azure/virtual-machines/linux/use-remote-desktop?tabs=azure-cli)  
[https://ubuntu.com/tutorials/access-remote-desktop#1-overview](https://ubuntu.com/tutorials/access-remote-desktop#1-overview)  


[https://docs.microsoft.com/en-us/powershell/module/az.resources/new-azresourcegroupdeployment?view=azps-8.1.0](https://docs.microsoft.com/en-us/powershell/module/az.resources/new-azresourcegroupdeployment?view=azps-8.1.0)  
[https://docs.microsoft.com/en-us/powershell/module/az.resources/new-azresourcegroup?view=azps-8.1.0](https://docs.microsoft.com/en-us/powershell/module/az.resources/new-azresourcegroup?view=azps-8.1.0)  
[https://docs.microsoft.com/en-us/powershell/module/az.compute/new-azvm?view=azps-8.1.0](https://docs.microsoft.com/en-us/powershell/module/az.compute/new-azvm?view=azps-8.1.0)  

[https://docs.microsoft.com/en-us/powershell/module/az.accounts/connect-azaccount?view=azps-8.1.0](https://docs.microsoft.com/en-us/powershell/module/az.accounts/connect-azaccount?view=azps-8.1.0)  




[https://docs.microsoft.com/en-us/cli/azure/reference-index?view=azure-cli-latest](https://docs.microsoft.com/en-us/cli/azure/reference-index?view=azure-cli-latest)  

[https://docs.microsoft.com/en-us/cli/azure/group?view=azure-cli-latest](https://docs.microsoft.com/en-us/cli/azure/group?view=azure-cli-latest)  
[https://docs.microsoft.com/en-us/cli/azure/vm?view=azure-cli-latest](https://docs.microsoft.com/en-us/cli/azure/vm?view=azure-cli-latest)  


[https://docs.microsoft.com/en-us/powershell/azure/get-started-azureps?view=azps-8.1.0](https://docs.microsoft.com/en-us/powershell/azure/get-started-azureps?view=azps-8.1.0)  


[https://azure.microsoft.com/en-in/services/api-management/](https://azure.microsoft.com/en-in/services/api-management/)  

[https://azure.microsoft.com/en-us/solutions/scaling-out-vs-scaling-up/#scale-up-vertically](https://azure.microsoft.com/en-us/solutions/scaling-out-vs-scaling-up/#scale-up-vertically)  



[https://docs.microsoft.com/en-us/azure/app-service/deploy-best-practices](https://docs.microsoft.com/en-us/azure/app-service/deploy-best-practices)  
[https://docs.microsoft.com/en-us/azure/app-service/deploy-continuous-deployment?tabs=github](https://docs.microsoft.com/en-us/azure/app-service/deploy-continuous-deployment?tabs=github)  
[https://stackify.com/azure-deployment-slots/](https://stackify.com/azure-deployment-slots/)  




[https://docs.microsoft.com/en-us/cli/azure/webapp?view=azure-cli-latest](https://docs.microsoft.com/en-us/cli/azure/webapp?view=azure-cli-latest)  
[https://docs.microsoft.com/en-us/powershell/module/az.websites/new-azappserviceplan?view=azps-8.1.0](https://docs.microsoft.com/en-us/powershell/module/az.websites/new-azappserviceplan?view=azps-8.1.0)  
[https://docs.microsoft.com/en-us/powershell/module/az.websites/new-azwebapp?view=azps-8.1.0](https://docs.microsoft.com/en-us/powershell/module/az.websites/new-azwebapp?view=azps-8.1.0)  


[https://docs.microsoft.com/en-us/cli/azure/appservice/plan?view=azure-cli-latest](https://docs.microsoft.com/en-us/cli/azure/appservice/plan?view=azure-cli-latest)  



[https://docs.microsoft.com/en-us/graph/overview](https://docs.microsoft.com/en-us/graph/overview)  
[https://docs.microsoft.com/en-us/azure/app-service/troubleshoot-diagnostic-logs](https://docs.microsoft.com/en-us/azure/app-service/troubleshoot-diagnostic-logs)  


[https://docs.microsoft.com/en-us/azure/azure-functions/durable/durable-functions-overview?tabs=csharp](https://docs.microsoft.com/en-us/azure/azure-functions/durable/durable-functions-overview?tabs=csharp)  


[https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/scaling-redis-cluster-mode-enabled.html](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/scaling-redis-cluster-mode-enabled.html)  

[https://docs.microsoft.com/en-us/azure/event-grid/compare-messaging-services](https://docs.microsoft.com/en-us/azure/event-grid/compare-messaging-services)  



[https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy](https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy)   


[https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/overview](https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/overview)  

[https://docs.microsoft.com/en-us/learn/modules/capture-application-logs-app-service/2-enable-and-configure-app-service-application-logging](https://docs.microsoft.com/en-us/learn/modules/capture-application-logs-app-service/2-enable-and-configure-app-service-application-logging)  



[https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview](https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview)  



[https://docs.microsoft.com/en-us/azure/azure-functions/functions-custom-handlers](https://docs.microsoft.com/en-us/azure/azure-functions/functions-custom-handlers)  
[https://docs.microsoft.com/en-us/azure/azure-functions/durable/durable-functions-overview?tabs=csharp](https://docs.microsoft.com/en-us/azure/azure-functions/durable/durable-functions-overview?tabs=csharp)  
[https://docs.microsoft.com/en-us/azure/azure-functions/functions-triggers-bindings](https://docs.microsoft.com/en-us/azure/azure-functions/functions-triggers-bindings)  
[https://docs.microsoft.com/en-us/azure/azure-functions/durable/durable-functions-overview?tabs=csharp#monitoring](https://docs.microsoft.com/en-us/azure/azure-functions/durable/durable-functions-overview?tabs=csharp#monitoring)  




[https://docs.microsoft.com/en-us/azure/azure-functions/scripts/functions-cli-create-serverless](https://docs.microsoft.com/en-us/azure/azure-functions/scripts/functions-cli-create-serverless)  



[https://docs.microsoft.com/en-us/azure/azure-functions/functions-triggers-bindings?tabs=csharp](https://docs.microsoft.com/en-us/azure/azure-functions/functions-triggers-bindings?tabs=csharp)  



[https://github.com/MicrosoftDocs/azure-docs/blob/main/articles/app-service/environment/using-an-ase.md](https://github.com/MicrosoftDocs/azure-docs/blob/main/articles/app-service/environment/using-an-ase.md)  

[https://docs.microsoft.com/en-us/azure/active-directory/privileged-identity-management/pim-configure](https://docs.microsoft.com/en-us/azure/active-directory/privileged-identity-management/pim-configure)  

[https://docs.microsoft.com/en-us/azure/azure-sql/database/elastic-pool-overview?view=azuresql](https://docs.microsoft.com/en-us/azure/azure-sql/database/elastic-pool-overview?view=azuresql)  


[https://docs.microsoft.com/en-us/azure/azure-cache-for-redis/cache-how-to-premium-clustering](https://docs.microsoft.com/en-us/azure/azure-cache-for-redis/cache-how-to-premium-clustering)  


[https://docs.microsoft.com/en-us/azure/cdn/cdn-features](https://docs.microsoft.com/en-us/azure/cdn/cdn-features)  

[https://docs.microsoft.com/en-us/answers/questions/39015/azure-app-service-arr-affinity-auto-scaling-statef.html](https://docs.microsoft.com/en-us/answers/questions/39015/azure-app-service-arr-affinity-auto-scaling-statef.html)  


[https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-overview-what-is](https://docs.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-overview-what-is)  
[https://docs.microsoft.com/en-us/sql/relational-databases/polybase/polybase-guide?toc=%2Fazure%2Fsynapse-analytics%2Fsql-data-warehouse%2Ftoc.json&bc=%2Fazure%2Fsynapse-analytics%2Fsql-data-warehouse%2Fbreadcrumb%2Ftoc.json&view=azure-sqldw-latest&preserve-view=true](https://docs.microsoft.com/en-us/sql/relational-databases/polybase/polybase-guide?toc=%2Fazure%2Fsynapse-analytics%2Fsql-data-warehouse%2Ftoc.json&bc=%2Fazure%2Fsynapse-analytics%2Fsql-data-warehouse%2Fbreadcrumb%2Ftoc.json&view=azure-sqldw-latest&preserve-view=true)  



