# Devops_Bench


## Objectives 

1. Architecting Cloud Native, Multi-Cloud and Polyglot Cloud applications that need to scale to millions.
2. Architecting Data Intensive and Big Data applications.
3. Building Machine and Deep learning pipelines and infrastructure.


```


Objectives 

1. Architecting Cloud Native, Multi-Cloud and Polyglot Cloud applications that need to scale to millions.
2. Architecting Data Intensive and Big Data applications.
3. Building Machine and Deep learning pipelines and infrastructure.



Requirements / Responsibilities

    Run the production environment by monitoring availability and taking a holistic view of system health
    Build software and systems to manage platform infrastructure and applications
    Improve reliability, quality, and time-to-market of our suite of software solutions
    Measure and optimize system performance, with an eye toward pushing our capabilities forward, getting ahead of customer needs, and innovating to continually improve
    Provide primary operational support and engineering for multiple large distributed software applications

Daily and Monthly Responsibilities

    Gather and analyze metrics from both operating systems and applications to assist in performance tuning and fault finding
    Partner with development teams to improve services through rigorous testing and release procedures
    Participate in system design consulting, platform management, and capacity planning
    Create sustainable systems and services through automation and uplifts
    Balance feature development speed and reliability with well-defined service level objectives

Required Skills and Qualifications

    Bachelor’s degree in computer science or other highly technical, scientific discipline
    Experience with distributed storage technologies like NFS, HDFS, Ceph, S3 as well as dynamic resource management frameworks (Mesos, Kubernetes, Yarn)
    A proactive approach to spotting problems, areas for improvement, and performance bottlenecks





    You have knowledge of protocols like HTTP, GRPC, TCP, and UDP and an understanding of TLS/SSL
    You understand operating system fundamentals

    Linux tooling and troubleshooting performance (pprof)
    networking stack, iptables (nmap, ngrep)
    systemd
    paging, memory allocation, tracing (dtrace, coredump)


    You understand containers and virtualization

    containerizing applications (docker, containerd)
    understanding of namespace, cgroups
    security (SELinux, eBPF)
    orchestration using Kubernetes


    You can write code and have experience in writing platform-level components. [ex golang, python]
    You have experience using SCM tools preferably, git
    You have worked with CI/CD tooling, automation using tools like terraform and ansible You have cloud experience on AWS or GCP


    You understand observability and logging

    worked with Prometheus and grafana
    used fluentd or loki and have experience handling logs at scale


    You have worked on large-scale systems and implemented DevOps practices at scale. You have worked on service meshes. eg. Istio, linkerd
    You have liaised with developers and have contributed to improving developer productivity You understand release engineering at scale on large teams.
    You are an excellent collaborator & communicator and you are able to mentor junior team members across the engineering org


    Bonus if you have advanced Kubernetes knowledge around

    writing CRDs
    multi-cluster and multi-tenant setup
    observability for large scale clusters



SRE Big Data  


Responsibilities:

        Design, code, test and deliver software to automate manual operational work
        Troubleshoot priority incidents, facilitate blameless post-mortems and ensure permanent closure of incidents
        Engage with development team throughout the life cycle to help develop software for reliability and scale, ensuring minimal refactoring or changes
        Identify application patterns and analytics in support of better service level objectives
        Design self-healing and resiliency patterns
        Design automated software and product upgrades, change management, and release management solutions
        Participate in the 24×7 support coverage as needed
        Mentor and guide junior developers

Requirements:

        Expertise in at least one technology stack designing, coding, testing, and delivering software
        Proficiency in one or more technology domains, may be a cross-domain expert able to solve complex and mission critical problems within a business or across the firm
        Working knowledge of infrastructure components (e.g. routers, load balancers , cloud products , container systems , compute, storage and networks)
        Excellent debugging and trouble shooting skills
        Prior experience in DevOps and/or application development teams
        Hands on experience using large scale software development, preferably in one of these languages: Java, Python, scripting languages
        Hands on experience of Kubernetes, Docker, Docker Swarm style deployments
        Exposure on data-dog and data-dog monitoring
        Hands on experience of Continuous Delivery tools
        Hands on experience in Unix: Linux and Solaris
        Exposure to Orchestration and configuration management tools for applications
        Experience with infrastructure components utilized in data warehousing or big data environments
        Excellent communication skills, both written and oral appropriately scaled for senior technical and senior business audience
        Ability to work and effectively prioritize in a highly dynamic work environment that includes a global focus




The Role

Tesla is on mission is to accelerate the world's transition to sustainable energy. We are looking for a Site Reliability Engineer to join our data platform team. We are a small, expert, cross-functional team made of data engineers and SREs. We are building a fairly large platform that other teams ranging from autopilot to service technicians leverage to collect and access data. We are already processing trillions of events per day but with more and more cars on the road, more and more Superchargers, Powerwalls, solar installations, new factories in China and Europe, and, of course, new products coming to markets, we need to think about scaling up our hybrid infrastructure to the next level.
What we are building

    We are building a hybrid platform with on-prem datacenters and public clouds in multiple regions.

    Our stack is fairly modern. Our services run in containers and we are taking advantage of everything we can in the cloud.

    The infrastructure is completely described and managed using infrastructure-as-code (IAC) and configuration management tools.

    We build and deploy over a hundred microservices using Bazel.

    At the data-layer, the stack is built on top of technologies including Spark, Kafka, and related.

    We develop tools in Python and Go to support predominately Java/Scala-based applications.

    For monitoring we use Prometheus, Grafana, Splunk and Cloudwatch

Responsibilities

You’ll work on high impact projects that improve data availability, scalability, and reliability of our data infrastructure.

    These days we are trying to expand our cloud infrastructure footprint

    We are also continuing our work around our builds and deployments pipelines.

    Occasionally, you will assist the Datacenter operation team with our on-prem presence as we plan for expansion and day to day operations.

    We also need to think about the next steps for our metrics systems which is currently under heavy load.

    Of course, you will also design, architect, improve and support new and existing tools to help us operate at scale.

    And, finally, join us in our oncall rotation.

Requirements

    You have a strong understanding of Linux, networking and production systems

    You have 3+ years of experience building and maintaining infrastructure and services or are a quick learner

    You are proficient at scripting and programming

    You have strong problem solving skills, optimizing for the simplest, most robust yet practical solutions

    You are reliable, dependable, trustworthy and, a participating team member

    You are smart but humble with a bias for action

Preferred

    You have strong proficiency with Go, Python, and/or Java

    You have experience with AWS or other cloud providers

    You have experienced large scale infrastructure

    You have used infrastructure as code tools such as Terraform, Cloudformation, Ansible, Puppet or Chef

    You have experience with observability tools such as Prometheus, Thanos, Cortex or Sensu

    You have experience with orchestration systems such as Kubernetes, Mesos or ECS

    You have worked in a service-oriented or microservice architecture

    You have experience with security and hardening, especially in a large or complex environment.

    You have experience designing, building and operating distributed systems at scale and/or willing to learn the stack: Kafka, Hadoop, HBase, Spark, etc.




```


Infrastructure  
```

bind  
squid  
linux machine  
route tables  
DNS route server  
dig  
dhcp
k8s ports
tcp port number  
nslookup 
k8s from scratch  
ldap
lvm


Open Stack  

trouble shooting  



Middleware  

Middleware is software which lies between an operating system and the applications running on it  





• Infrastructure expertise across multiple technologies including storage, server infrastructure, data center operations and virtualisation
• Strong experience with Linux/Unix
• Proficiency in one or more scripting languages (Perl/Python/Bash/Ruby)
• Experience in Mysql and any NoSQL database technology
• Monitoring and instrumentation setup and design
• Basic network debugging skills
• Understanding of TCP/IP stack and related protocols
• Deep understanding of Layer 7 protocols like HTTP, DHCP, DNS, SSL/TLS
• Excellent written and verbal communication skills
• Ability to work under pressure
• Ability to prioritize and manage time efficiently
• Sound soft skills to get along with colleagues from other teams in order to harness the development process
• Expertise in big data applications including Hadoop (CDH/HDP), Hive, Cassandra, Vertical ElasticSearch, etc is a BIG PLUS.
• Ability to break down a bigger problem into smaller chunks is an added advantage
• Advanced Network debugging skills with different tools  




```

